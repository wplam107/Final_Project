{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T19:25:53.757669Z",
     "start_time": "2020-04-27T19:25:44.099275Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import gensim\n",
    "import spacy\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pprint import pprint\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim import corpora, models\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import CoherenceModel\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import fe\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T19:25:57.391611Z",
     "start_time": "2020-04-27T19:25:57.358611Z"
    }
   },
   "outputs": [],
   "source": [
    "file = open('articles.p', 'rb')      \n",
    "df = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T19:25:58.311800Z",
     "start_time": "2020-04-27T19:25:58.302082Z"
    }
   },
   "outputs": [],
   "source": [
    "drop_indices = df.loc[df['date'] < pd.Timestamp(2019, 3, 15)].index\n",
    "df.drop(index=drop_indices, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T19:26:00.682839Z",
     "start_time": "2020-04-27T19:26:00.614918Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop update articles and investing articles\n",
    "df = df.loc[df['headline'].map(lambda x: re.search(r'UPDATE', x)).isna()]\n",
    "df = df.loc[df['headline'].map(lambda x: re.search(r'US STOCKS', x)).isna()]\n",
    "df = df.loc[df['headline'].map(lambda x: re.search(r'PRESS', x)).isna()]\n",
    "df = df.loc[df['url'].map(lambda x: re.search(r'/education/', x)).isna()]\n",
    "df = df.loc[df['url'].map(lambda x: re.search(r'/politics/', x)).isna()]\n",
    "df = df.loc[df['url'].map(lambda x: re.search(r'/diplomacy/', x)).isna()]\n",
    "df = df.loc[df['url'].map(lambda x: re.search(r'/letters/', x)).isna()]\n",
    "df = df.loc[df['url'].map(lambda x: re.search(r'health-', x)).isna()]\n",
    "df = df.loc[df['url'].map(lambda x: re.search(r'/money/', x)).isna()]\n",
    "df = df.loc[df['url'].map(lambda x: re.search(r'/transport/', x)).isna()]\n",
    "df = df.loc[df['url'].map(lambda x: re.search(r'investing', x)).isna()]\n",
    "df = df.loc[df['url'].map(lambda x: re.search(r'/society/', x)).isna()]\n",
    "df.reset_index(inplace=True)\n",
    "df.drop(columns='index', inplace=True)\n",
    "# df.drop(columns='url', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T19:26:01.913932Z",
     "start_time": "2020-04-27T19:26:01.903095Z"
    }
   },
   "outputs": [],
   "source": [
    "df['source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T19:26:05.435010Z",
     "start_time": "2020-04-27T19:26:05.430305Z"
    }
   },
   "outputs": [],
   "source": [
    "df_urls = df['url']\n",
    "df.drop(columns='url', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T04:13:31.271888Z",
     "start_time": "2020-04-14T04:13:31.266874Z"
    }
   },
   "outputs": [],
   "source": [
    "# file = open('df_urls.p', 'wb')      \n",
    "# pickle.dump(df_urls, file)\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add sentences and words features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T19:26:15.664863Z",
     "start_time": "2020-04-27T19:26:15.605985Z"
    }
   },
   "outputs": [],
   "source": [
    "# Additional cleaning of body of article\n",
    "df['body'] = df['body'].map(fe.replace_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T19:26:18.419000Z",
     "start_time": "2020-04-27T19:26:17.221010Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create sentence feature\n",
    "df['sentences'] = df['body'].map(lambda x: sent_tokenize(x)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T19:26:21.339969Z",
     "start_time": "2020-04-27T19:26:20.189133Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocess sentences\n",
    "df['sentence_tokens'] = df['sentences'].map(fe.preprocess_sent)\n",
    "\n",
    "# Preprocess entire body for training\n",
    "df['word_tokens'] = df['sentence_tokens'].map(lambda x: [ item for l in x for item in l ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary and bigram models\n",
    "- This section heavily borrows from https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T19:26:35.870952Z",
     "start_time": "2020-04-27T19:26:24.758665Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create bigrams in df['word_tokens']\n",
    "df['word_tokens'] = df['word_tokens'].map(fe.make_bigrams)\n",
    "\n",
    "# Create bigrams in df['sentence_tokens']\n",
    "df['sentence_tokens'] = df['sentence_tokens'].map(fe.make_bigrams_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T19:27:25.090884Z",
     "start_time": "2020-04-27T19:26:35.874048Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lemmatize df['word_tokens']\n",
    "df['word_tokens'] = df['word_tokens'].map(fe.lemmatization)\n",
    "\n",
    "# Lemmatize df['sentence_tokens']\n",
    "df['sentence_tokens'] = df['sentence_tokens'].map(fe.lemmatize_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T19:27:25.101616Z",
     "start_time": "2020-04-27T19:27:25.093115Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split into SCMP and not SCMP\n",
    "df1 = df.loc[df['source'] == 'SCMP'] # SCMP\n",
    "df2 = df.loc[df['source'] != 'SCMP'] # Not SCMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T19:27:25.110369Z",
     "start_time": "2020-04-27T19:27:25.105450Z"
    }
   },
   "outputs": [],
   "source": [
    "# Choose corpus for training\n",
    "data_lemmatized = df2['word_tokens'] # Not SCMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T19:27:25.379863Z",
     "start_time": "2020-04-27T19:27:25.118937Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Filter extremes from dictionary\n",
    "id2word.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [ id2word.doc2bow(text) for text in texts ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T19:27:25.406852Z",
     "start_time": "2020-04-27T19:27:25.384671Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create TF-IDF corpus\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T19:27:25.419232Z",
     "start_time": "2020-04-27T19:27:25.411379Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pickle id2word\n",
    "# file = open('id2word.p', 'wb')      \n",
    "# pickle.dump(id2word, file)\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T19:28:04.626867Z",
     "start_time": "2020-04-27T19:27:40.383252Z"
    }
   },
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       workers=2,\n",
    "                                       num_topics=4, \n",
    "                                       random_state=100,\n",
    "                                       passes=10,\n",
    "                                       per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T19:28:04.637576Z",
     "start_time": "2020-04-27T19:28:04.630947Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T19:28:06.591193Z",
     "start_time": "2020-04-27T19:28:04.640511Z"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "- Topics:\n",
    "    - Topic 0: Protests\n",
    "    - Topic 1: Economic\n",
    "    - Topic 2: Government"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T19:28:15.804554Z",
     "start_time": "2020-04-27T19:28:07.317218Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_lda_model = gensim.models.LdaMulticore(corpus=corpus_tfidf,\n",
    "                                             id2word=id2word,\n",
    "                                             workers=4,\n",
    "                                             num_topics=4,\n",
    "                                             chunksize=100,\n",
    "                                             random_state=100,\n",
    "                                             passes=10,\n",
    "                                             per_word_topics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T19:28:15.815635Z",
     "start_time": "2020-04-27T19:28:15.808526Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pprint(tfidf_lda_model.print_topics())\n",
    "doc_tfidf_lda = tfidf_lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T19:28:17.947525Z",
     "start_time": "2020-04-27T19:28:15.821467Z"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nPerplexity: ', tfidf_lda_model.log_perplexity(corpus))\n",
    "\n",
    "coherence_model_tfidf_lda = CoherenceModel(model=tfidf_lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_tfidf_lda = coherence_model_tfidf_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_tfidf_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "- Topics:\n",
    "    - Topic 0: Government\n",
    "    - Topic 1: Legal Issues\n",
    "    - Topic 2: Economic\n",
    "    - Topic 3: Protests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA Mallet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T19:28:17.953483Z",
     "start_time": "2020-04-27T19:28:17.950104Z"
    }
   },
   "outputs": [],
   "source": [
    "mallet_path = '/Users/waynelam/Documents/DevStuff/mallet-2.0.8/bin/mallet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T19:28:55.468879Z",
     "start_time": "2020-04-27T19:28:17.957438Z"
    }
   },
   "outputs": [],
   "source": [
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path,\n",
    "                                             corpus=corpus,\n",
    "                                             random_seed=123,\n",
    "                                             num_topics=4,\n",
    "                                             id2word=id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T19:28:55.479859Z",
     "start_time": "2020-04-27T19:28:55.473131Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pprint(ldamallet.show_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T19:28:56.369489Z",
     "start_time": "2020-04-27T19:28:55.483759Z"
    }
   },
   "outputs": [],
   "source": [
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet,\n",
    "                                           texts=data_lemmatized,\n",
    "                                           dictionary=id2word,\n",
    "                                           coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_ldamallet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "- Topics:\n",
    "    - Topic 0: Protest\n",
    "    - Topic 1: Economy\n",
    "    - Topic 2: Politics\n",
    "    - Topic 3: Government"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T19:34:36.920238Z",
     "start_time": "2020-04-27T19:28:56.372359Z"
    }
   },
   "outputs": [],
   "source": [
    "model_list, coherence_values = fe.compute_coherence_values(id2word,\n",
    "                                                           corpus,\n",
    "                                                           data_lemmatized,\n",
    "                                                           start=3,\n",
    "                                                           limit=15,\n",
    "                                                           step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T19:34:36.923862Z",
     "start_time": "2020-04-27T19:28:54.455Z"
    }
   },
   "outputs": [],
   "source": [
    "limit = 15\n",
    "start = 3\n",
    "step = 1\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T19:34:36.926180Z",
     "start_time": "2020-04-27T19:28:55.262Z"
    }
   },
   "outputs": [],
   "source": [
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T19:34:36.927989Z",
     "start_time": "2020-04-27T19:29:02.231Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use weights from LDA Mallet and transfer to standard LDA Model\n",
    "mallet_model = gensim.models.wrappers.ldamallet.malletmodel2ldamodel(ldamallet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T04:09:26.415079Z",
     "start_time": "2020-04-14T04:09:26.412186Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pyLDAvis.enable_notebook()\n",
    "# vis = pyLDAvis.gensim.prepare(mallet_model, corpus, id2word)\n",
    "# vis.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:24:37.713607Z",
     "start_time": "2020-04-08T14:24:37.707187Z"
    }
   },
   "outputs": [],
   "source": [
    "pyLDAvis.save_html(vis, 'topic_words.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T01:57:33.870698Z",
     "start_time": "2020-04-08T01:57:33.863970Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pickle LDA Mallet model\n",
    "# file = open('mallet.p', 'wb')      \n",
    "# pickle.dump(mallet_model, file)\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T01:56:41.310968Z",
     "start_time": "2020-04-08T01:56:41.305574Z"
    }
   },
   "outputs": [],
   "source": [
    "# file = open('ldavis.p', 'wb')      \n",
    "# pickle.dump(vis, file)\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T00:58:50.930396Z",
     "start_time": "2020-04-08T00:58:50.849789Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create column for sentiment analysis\n",
    "# Sentences for sentiment analysis and sentence_tokens for topic analysis\n",
    "s = df['sentences']\n",
    "st = df['sentence_tokens']\n",
    "\n",
    "combine = []\n",
    "for i in range(len(s)):\n",
    "    total = []\n",
    "    total.append(s[i])\n",
    "    total.append(st[i])\n",
    "    combine.append(total)\n",
    "\n",
    "df['combine'] = combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T21:59:59.416887Z",
     "start_time": "2020-04-08T21:57:19.817826Z"
    }
   },
   "outputs": [],
   "source": [
    "df['sentiment'] = df['combine'].map(fe.sentiment_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic 0: Protests\n",
    "# Topic 1: Econ\n",
    "# Topic 2: Poli\n",
    "# Topic 3: Gov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T21:59:59.438733Z",
     "start_time": "2020-04-08T21:59:59.419964Z"
    }
   },
   "outputs": [],
   "source": [
    "# Map sentiment scores into columns\n",
    "df['protest'] = df['sentiment'].map(lambda x: x[0][0])\n",
    "df['econ'] = df['sentiment'].map(lambda x: x[1][0])\n",
    "df['poli'] = df['sentiment'].map(lambda x: x[2][0])\n",
    "df['gov'] = df['sentiment'].map(lambda x: x[3][0])\n",
    "df['protest_mention'] = df['sentiment'].map(lambda x: x[0][1])\n",
    "df['econ_mention'] = df['sentiment'].map(lambda x: x[1][1])\n",
    "df['poli_mention'] = df['sentiment'].map(lambda x: x[2][1])\n",
    "df['gov_mention'] = df['sentiment'].map(lambda x: x[3][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T21:59:59.447638Z",
     "start_time": "2020-04-08T21:59:59.441726Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create total sentences column\n",
    "df['total_sentences'] = df['protest_mention'] + df['econ_mention'] + df['poli_mention'] + df['gov_mention']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T21:59:59.458751Z",
     "start_time": "2020-04-08T21:59:59.450278Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create weighted scores\n",
    "df['w_protest'] = df['protest'] * (df['protest_mention'] / df['total_sentences'])\n",
    "df['w_econ'] = df['econ'] * (df['econ_mention'] / df['total_sentences'])\n",
    "df['w_gov'] = df['gov'] * (df['gov_mention'] / df['total_sentences'])\n",
    "df['w_poli'] = df['poli'] * (df['poli_mention'] / df['total_sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T19:21:25.121531Z",
     "start_time": "2020-04-08T19:21:24.685292Z"
    }
   },
   "outputs": [],
   "source": [
    "# file = open('dataframe.p', 'wb')      \n",
    "# pickle.dump(df, file)\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T21:59:59.470202Z",
     "start_time": "2020-04-08T21:59:59.460835Z"
    }
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(pd.concat([df.iloc[:, 3:4], df.iloc[:, 9:]], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T22:00:18.543274Z",
     "start_time": "2020-04-08T21:59:59.472360Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sentiment analysis of headline\n",
    "df2['hl_sent'] = df['headline'].map(lambda x: abs(vader_analysis(x)['compound']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T19:21:46.506873Z",
     "start_time": "2020-04-08T19:21:46.476219Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.groupby('source')['hl_sent'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T22:00:18.556945Z",
     "start_time": "2020-04-08T22:00:18.546089Z"
    }
   },
   "outputs": [],
   "source": [
    "df2['protest_ratio'] = df2['protest_mention'] / df2['total_sentences']\n",
    "df2['econ_ratio'] = df2['econ_mention'] / df2['total_sentences']\n",
    "df2['poli_ratio'] = df2['poli_mention'] / df2['total_sentences']\n",
    "df2['gov_ratio'] = df2['gov_mention'] / df2['total_sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T19:22:39.505914Z",
     "start_time": "2020-04-08T19:22:39.483625Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T19:22:47.881685Z",
     "start_time": "2020-04-08T19:22:47.864435Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df2.iloc[:, 1:5].values\n",
    "X = RobustScaler().fit_transform(X)\n",
    "y = df2['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T19:22:54.309532Z",
     "start_time": "2020-04-08T19:22:54.306328Z"
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T19:22:55.600231Z",
     "start_time": "2020-04-08T19:22:55.593703Z"
    }
   },
   "outputs": [],
   "source": [
    "components = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T19:22:56.573516Z",
     "start_time": "2020-04-08T19:22:56.569688Z"
    }
   },
   "outputs": [],
   "source": [
    "comp_df = pd.DataFrame(data = components, columns = ['pc1', 'pc2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T19:22:57.262741Z",
     "start_time": "2020-04-08T19:22:57.258410Z"
    }
   },
   "outputs": [],
   "source": [
    "comp_df['source'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T19:22:57.994124Z",
     "start_time": "2020-04-08T19:22:57.987391Z"
    }
   },
   "outputs": [],
   "source": [
    "cond1 = (comp_df['source'] == 'CNN')\n",
    "cond2 = (comp_df['source'] == 'ABC (Australia)')\n",
    "cond3 = (comp_df['source'] == 'CCTV')\n",
    "cond4 = (comp_df['source'] == 'Reuters')\n",
    "cond5 = (comp_df['source'] == 'SCMP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T19:22:59.575508Z",
     "start_time": "2020-04-08T19:22:59.540157Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.groupby('source').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T19:23:02.638413Z",
     "start_time": "2020-04-08T19:23:02.258792Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,10))\n",
    "sns.scatterplot(x='pc1', y='pc2', hue='source', alpha=0.5, data=comp_df.loc[cond4 | cond5 | cond3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T03:05:08.324901Z",
     "start_time": "2020-04-08T03:05:08.094110Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,10))\n",
    "pd.value_counts(df2['source']).plot.bar()\n",
    "plt.title('Article Counts by Source')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T03:50:28.994774Z",
     "start_time": "2020-04-08T03:50:28.682436Z"
    }
   },
   "outputs": [],
   "source": [
    "ratios = ['gov_ratio', 'econ_ratio', 'poli_ratio', 'protest_ratio']\n",
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "df2.groupby('source').mean()[ratios].plot(ax=ax, kind='bar')\n",
    "plt.title('Mean Topic Ratios of Articles by Source')\n",
    "plt.xlabel('Source')\n",
    "plt.ylabel('% of Article')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T03:17:13.782175Z",
     "start_time": "2020-04-08T03:17:13.775647Z"
    }
   },
   "outputs": [],
   "source": [
    "ratios = ['protest_ratio', 'econ_ratio', 'poli_ratio', 'gov_ratio']\n",
    "df_ratio = df2.loc[:, features]\n",
    "df_ratio['source'] = df2['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T03:41:37.355151Z",
     "start_time": "2020-04-08T03:41:37.327658Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.groupby('source').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T03:21:43.015782Z",
     "start_time": "2020-04-08T03:21:43.009540Z"
    }
   },
   "outputs": [],
   "source": [
    "features = ['protest_ratio', 'econ_ratio', 'poli_ratio', 'gov_ratio']\n",
    "X2 = df2.loc[:, features].values\n",
    "X2 = MinMaxScaler().fit_transform(X2)\n",
    "y = df2['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T03:21:44.191194Z",
     "start_time": "2020-04-08T03:21:44.184918Z"
    }
   },
   "outputs": [],
   "source": [
    "comp2 = pca.fit_transform(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T03:21:44.829436Z",
     "start_time": "2020-04-08T03:21:44.824832Z"
    }
   },
   "outputs": [],
   "source": [
    "comp2_df = pd.DataFrame(data = comp2, columns = ['pc1', 'pc2'])\n",
    "comp2_df['source'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T03:21:45.352289Z",
     "start_time": "2020-04-08T03:21:45.344908Z"
    }
   },
   "outputs": [],
   "source": [
    "cond1 = (comp2_df['source'] == 'CNN')\n",
    "cond2 = (comp2_df['source'] == 'ABC (Australia)')\n",
    "cond3 = (comp2_df['source'] == 'CCTV')\n",
    "cond4 = (comp2_df['source'] == 'Reuters')\n",
    "cond5 = (comp2_df['source'] == 'SCMP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T03:21:59.804222Z",
     "start_time": "2020-04-08T03:21:59.401126Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,10))\n",
    "sns.scatterplot(x='pc1', y='pc2', hue='source', alpha=0.5, data=comp2_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:27:51.356576Z",
     "start_time": "2020-04-08T14:27:51.026224Z"
    }
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:28:10.547460Z",
     "start_time": "2020-04-08T14:28:05.442013Z"
    }
   },
   "outputs": [],
   "source": [
    "# Word cloud visualization\n",
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]  # more colors: 'mcolors.XKCD_COLORS'\n",
    "\n",
    "cloud = WordCloud(stopwords=stop_words,\n",
    "                  background_color='white',\n",
    "                  width=2500,\n",
    "                  height=1800,\n",
    "                  max_words=10,\n",
    "                  colormap='tab10',\n",
    "                  color_func=lambda *args, **kwargs: cols[i],\n",
    "                  prefer_horizontal=1.0)\n",
    "\n",
    "topics = mallet_model.show_topics(formatted=False)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10,10), sharex=True, sharey=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    fig.add_subplot(ax)\n",
    "    topic_words = dict(topics[i][1])\n",
    "    cloud.generate_from_frequencies(topic_words, max_font_size=300)\n",
    "    plt.gca().imshow(cloud)\n",
    "    plt.gca().set_title('Topic ' + str(i), fontdict=dict(size=16))\n",
    "    plt.gca().axis('off')\n",
    "\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.axis('off')\n",
    "plt.margins(x=0, y=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T22:00:18.566324Z",
     "start_time": "2020-04-08T22:00:18.560613Z"
    }
   },
   "outputs": [],
   "source": [
    "# file = open('data.p', 'wb')      \n",
    "# pickle.dump(df2, file)\n",
    "# file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
